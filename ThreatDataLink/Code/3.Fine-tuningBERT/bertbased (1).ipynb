{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch transformers pandas numpy matplotlib seaborn scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T13:14:36.320494Z",
     "iopub.status.busy": "2025-04-12T13:14:36.319782Z",
     "iopub.status.idle": "2025-04-12T13:50:44.023174Z",
     "shell.execute_reply": "2025-04-12T13:50:44.022385Z",
     "shell.execute_reply.started": "2025-04-12T13:14:36.320468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SRL dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SRL data: 100%|██████████| 6759/6759 [00:01<00:00, 4927.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6759 valid samples\n",
      "Train: 4731, Validation: 1014, Test: 1014\n",
      "Train label distribution: {0: 3581, 1: 1150}\n",
      "Val label distribution: {0: 767, 1: 247}\n",
      "Test label distribution: {0: 767, 1: 247}\n",
      "No pre-trained model found. Training a new model...\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:  14%|█▍        | 41/296 [03:21<20:52,  4.91s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 783\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;66;03m# Run the main function if this script is executed directly\u001b[39;00m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 675\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo pre-trained model found. Training a new model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     model = \u001b[43mtrain_hinge_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmargin\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontrastive_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;66;03m# Create test dataset and dataloader\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPreparing test data...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 373\u001b[39m, in \u001b[36mtrain_hinge_model\u001b[39m\u001b[34m(train_df, val_df, epochs, batch_size, margin, patience, lr, contrastive_weight)\u001b[39m\n\u001b[32m    370\u001b[39m hinge_loss = criterion(outputs, labels, weights)\n\u001b[32m    371\u001b[39m total_loss = hinge_loss + cont_loss * model.contrastive_weight\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m \u001b[43mtotal_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m optimizer.step()\n\u001b[32m    376\u001b[39m train_loss += total_loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LinkingCVE/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LinkingCVE/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LinkingCVE/venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ======================== Enhanced Core Components ========================\n",
    "\n",
    "# 1. Data Preparation & SRL Processing\n",
    "class SRLProcessor:\n",
    "    def __init__(self):\n",
    "        self.role_tags = {\n",
    "            'V': 'verb', 'ARG0': 'subject', 'ARG1': 'object',\n",
    "            'ARG2': 'indirect-object', 'ARGM-MNR': 'manner'\n",
    "        }\n",
    "    \n",
    "    def process_srl(self, srl_data):\n",
    "        \"\"\"Process SRL data and add semantic role labels to text\"\"\"\n",
    "        augmented = []\n",
    "        for sent_info in srl_data:\n",
    "            if 'srl_raw' not in sent_info or 'words' not in sent_info['srl_raw']:\n",
    "                continue  # Skip malformed entries\n",
    "                \n",
    "            words = sent_info['srl_raw']['words']\n",
    "            tags = [[] for _ in words]\n",
    "            \n",
    "            # Process each verb and its tags\n",
    "            for verb_info in sent_info['srl_raw'].get('verbs', []):\n",
    "                if 'tags' not in verb_info:\n",
    "                    continue\n",
    "                    \n",
    "                current_tags = verb_info['tags']\n",
    "                for idx, tag in enumerate(current_tags):\n",
    "                    if idx >= len(tags):  # Prevent index error\n",
    "                        break\n",
    "                    if tag != 'O' and '-' in tag:\n",
    "                        role = tag.split('-')[1]\n",
    "                        if role in self.role_tags:  # Only add if it's in our defined roles\n",
    "                            tags[idx].append(role)\n",
    "            \n",
    "            # Build the tagged sentence\n",
    "            tagged_sentence = []\n",
    "            for word, roles in zip(words, tags):\n",
    "                for role in roles:\n",
    "                    if role in self.role_tags:\n",
    "                        tagged_sentence.append(f\"[{self.role_tags[role]}]\")\n",
    "                tagged_sentence.append(word)\n",
    "                for role in reversed(roles):\n",
    "                    if role in self.role_tags:\n",
    "                        tagged_sentence.append(f\"[/{self.role_tags[role]}]\")\n",
    "            \n",
    "            augmented.append(' '.join(tagged_sentence))\n",
    "        \n",
    "        return ' '.join(augmented)\n",
    "\n",
    "def load_srl_dataset(json_path):\n",
    "    \"\"\"Load dataset from JSON and apply SRL processing\"\"\"\n",
    "    try:\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f).get('samples', [])\n",
    "    except (json.JSONDecodeError, FileNotFoundError) as e:\n",
    "        print(f\"Error loading JSON data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    processor = SRLProcessor()\n",
    "    samples = []\n",
    "    \n",
    "    for sample in tqdm(data, desc=\"Processing SRL data\"):\n",
    "        try:\n",
    "            samples.append({\n",
    "                'CVE_text': processor.process_srl(sample.get('CVE_srl', [])),\n",
    "                'Technique_text': processor.process_srl(sample.get('Technique_srl', [])),\n",
    "                'label': sample.get('label', 0),\n",
    "                'role_score': sample.get('role_match_score', 0.0)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample: {e}\")\n",
    "            continue\n",
    "    \n",
    "    df = pd.DataFrame(samples)\n",
    "    print(f\"Loaded {len(df)} valid samples\")\n",
    "    return df\n",
    "\n",
    "# 2. Dataset Class with Hinge Labels\n",
    "class HingeSiameseDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # Normalize role weights to [0,1]\n",
    "        if len(df) > 0:  # Check if df is not empty\n",
    "            role_min = df['role_score'].min()\n",
    "            role_max = df['role_score'].max()\n",
    "            self.role_weights = (df['role_score'] - role_min) / (role_max - role_min + 1e-8)\n",
    "            \n",
    "            # Convert to -1/1 labels for hinge loss\n",
    "            self.labels = 2 * df['label'].values - 1\n",
    "        else:\n",
    "            self.role_weights = pd.Series()\n",
    "            self.labels = np.array([])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Tokenize CVE text\n",
    "        cve_encodings = self.tokenizer(\n",
    "            row['CVE_text'], \n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize Technique text\n",
    "        tech_encodings = self.tokenizer(\n",
    "            row['Technique_text'],\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'cve_input_ids': cve_encodings['input_ids'].squeeze(),\n",
    "            'cve_attention_mask': cve_encodings['attention_mask'].squeeze(),\n",
    "            'tech_input_ids': tech_encodings['input_ids'].squeeze(),\n",
    "            'tech_attention_mask': tech_encodings['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float),\n",
    "            'role_weights': torch.tensor(self.role_weights.iloc[idx], dtype=torch.float),\n",
    "            'CVE_text': row['CVE_text'],\n",
    "            'Technique_text': row['Technique_text']\n",
    "        }\n",
    "\n",
    "# 3. Enhanced Model Architecture with Contrastive Learning\n",
    "class EnhancedContrastiveSRLModel(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", hidden_size=768, margin=0.4, contrastive_weight=0.3):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.bert = AutoModel.from_pretrained(model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pretrained model: {e}\")\n",
    "            raise RuntimeError(\"Failed to initialize the model\")\n",
    "        \n",
    "        # Projection layer remains unchanged\n",
    "        self.srl_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256)\n",
    "        )\n",
    "        \n",
    "        # Classifier using aggregation of embeddings and interaction features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        self.contrastive_loss = nn.CosineEmbeddingLoss(margin=margin)\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "\n",
    "    def soft_align_attention(self, a, b, mask_a, mask_b):\n",
    "        \"\"\"\n",
    "        Compute soft-alignment between two sequences:\n",
    "          a: [batch, seq_len_a, hidden]\n",
    "          b: [batch, seq_len_b, hidden]\n",
    "          mask_a: [batch, seq_len_a]\n",
    "          mask_b: [batch, seq_len_b]\n",
    "        Returns:\n",
    "          aligned_a: weighted sum of b for each token in a\n",
    "          aligned_b: weighted sum of a for each token in b\n",
    "        \"\"\"\n",
    "        # Compute similarity matrix [B, L_a, L_b]\n",
    "        similarity = torch.bmm(a, b.transpose(1, 2))\n",
    "        \n",
    "        # Create proper broadcasting dimensions for masks\n",
    "        batch_size = mask_b.size(0)\n",
    "        seq_len_a = similarity.size(1)\n",
    "        seq_len_b = similarity.size(2)\n",
    "        \n",
    "        # Masking the padded tokens in b for computing attention on a's tokens\n",
    "        mask_b_exp = mask_b.unsqueeze(1).expand(batch_size, seq_len_a, seq_len_b)\n",
    "        attn_weights_a = F.softmax(similarity.masked_fill(mask_b_exp == 0, -1e9), dim=2)\n",
    "        \n",
    "        # Similarly, compute attention weights for b (using a's mask)\n",
    "        mask_a_exp = mask_a.unsqueeze(2).expand(batch_size, seq_len_a, seq_len_b)\n",
    "        attn_weights_b = F.softmax(similarity.transpose(1,2).masked_fill(mask_a_exp == 0, -1e9), dim=2)\n",
    "        \n",
    "        aligned_a = torch.bmm(attn_weights_a, b)  # [B, L_a, hidden]\n",
    "        aligned_b = torch.bmm(attn_weights_b, a)  # [B, L_b, hidden]\n",
    "        return aligned_a, aligned_b\n",
    "\n",
    "    def pooling(self, token_embeddings, mask):\n",
    "        \"\"\"\n",
    "        Apply masked average pooling to token embeddings.\n",
    "          token_embeddings: [B, L, hidden]\n",
    "          mask: [B, L] with 1 for valid tokens and 0 for padding.\n",
    "        Returns:\n",
    "          pooled embedding [B, hidden]\n",
    "        \"\"\"\n",
    "        mask = mask.unsqueeze(2).float()  # [B, L, 1]\n",
    "        summed = torch.sum(token_embeddings * mask, dim=1)\n",
    "        counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        \n",
    "        # Add safety check for cases where mask is all zeros\n",
    "        valid_counts = (counts > 1e-8).float()\n",
    "        return (summed / counts) * valid_counts\n",
    "\n",
    "    def forward(self, cve_input, tech_input, labels=None):\n",
    "        # Encode inputs\n",
    "        cve_outputs = self.bert(**cve_input)       # shape: [B, L_cve, hidden_size]\n",
    "        tech_outputs = self.bert(**tech_input)     # shape: [B, L_tech, hidden_size]\n",
    "        \n",
    "        cve_seq = cve_outputs.last_hidden_state\n",
    "        tech_seq = tech_outputs.last_hidden_state\n",
    "        \n",
    "        # Get the attention masks from inputs\n",
    "        cve_mask = cve_input['attention_mask']     # [B, L_cve]\n",
    "        tech_mask = tech_input['attention_mask']   # [B, L_tech]\n",
    "        \n",
    "        # -----------------------\n",
    "        # Add: Soft Align Attention\n",
    "        # -----------------------\n",
    "        aligned_cve, aligned_tech = self.soft_align_attention(cve_seq, tech_seq, cve_mask, tech_mask)\n",
    "        \n",
    "        # Combine the original sequence with the aligned one (e.g., by averaging)\n",
    "        cve_combined = (cve_seq + aligned_cve) / 2.0\n",
    "        tech_combined = (tech_seq + aligned_tech) / 2.0\n",
    "        \n",
    "        # -----------------------\n",
    "        # Add: Pooling over the token dimension\n",
    "        # -----------------------\n",
    "        cve_pooled = self.pooling(cve_combined, cve_mask)   # [B, hidden_size]\n",
    "        tech_pooled = self.pooling(tech_combined, tech_mask)  # [B, hidden_size]\n",
    "        \n",
    "        # -----------------------\n",
    "        # Apply projection to lower-dimensional embeddings\n",
    "        # -----------------------\n",
    "        cve_emb = self.srl_proj(cve_pooled)   # [B, 256]\n",
    "        tech_emb = self.srl_proj(tech_pooled)   # [B, 256]\n",
    "        \n",
    "        # -----------------------\n",
    "        # Aggregating features from both branches\n",
    "        # -----------------------\n",
    "        diff = torch.abs(cve_emb - tech_emb)\n",
    "        prod = cve_emb * tech_emb\n",
    "        combined_features = torch.cat([cve_emb, tech_emb, diff, prod], dim=1)  # [B, 256*4]\n",
    "        \n",
    "        # Compute classifier output (similarity score or decision)\n",
    "        classifier_out = self.classifier(combined_features).squeeze()\n",
    "        \n",
    "        # In case labels is None (inference mode)\n",
    "        cont_loss = torch.tensor(0.0, device=classifier_out.device)\n",
    "        \n",
    "        # Optionally, compute contrastive loss if labels provided\n",
    "        if labels is not None:\n",
    "            contrastive_labels = torch.where(labels > 0, 1.0, -1.0).to(labels.device)\n",
    "            cont_loss = self.contrastive_loss(cve_emb, tech_emb, contrastive_labels)\n",
    "        \n",
    "        # Always return both values to maintain consistent return structure\n",
    "        return classifier_out, cont_loss\n",
    "\n",
    "    def get_embeddings(self, input_dict):\n",
    "        # Compute embeddings for inference (using pooling, projection)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(**input_dict)\n",
    "            pooled = self.pooling(outputs.last_hidden_state, input_dict['attention_mask'])\n",
    "            return self.srl_proj(pooled).cpu().numpy()\n",
    "\n",
    "# 4. Enhanced Hinge Loss with Weighting\n",
    "class WeightedHingeLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, outputs, labels, weights):\n",
    "        losses = torch.clamp(self.margin - labels * outputs, min=0)\n",
    "        return (losses * (1 + weights)).mean()\n",
    "\n",
    "# 6. Data Splitting with Stratification\n",
    "def get_splits_for_model(df, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"Split data into train/val/test with stratification\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty, cannot split\")\n",
    "        \n",
    "    # First split off the test set\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, random_state=random_state, stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    # Then split the remaining data into train and validation\n",
    "    relative_val_size = val_size / (1 - test_size)\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, \n",
    "        test_size=relative_val_size, \n",
    "        random_state=random_state,\n",
    "        stratify=train_val_df['label']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n",
    "    print(f\"Train label distribution: {train_df['label'].value_counts().to_dict()}\")\n",
    "    print(f\"Val label distribution: {val_df['label'].value_counts().to_dict()}\")\n",
    "    print(f\"Test label distribution: {test_df['label'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# 7. Enhanced Training with Contrastive Loss\n",
    "def train_hinge_model(train_df, val_df=None, epochs=10, batch_size=16, \n",
    "                      margin=1.0, patience=3, lr=2e-5, contrastive_weight=0.4):\n",
    "    \"\"\"Train model with contrastive learning objective using the enhanced model with soft-align attention\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Use the enhanced model that now includes soft-align attention, pooling, and aggregation\n",
    "    model = EnhancedContrastiveSRLModel(contrastive_weight=contrastive_weight).to(device)\n",
    "    \n",
    "    train_dataset = HingeSiameseDataset(train_df, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    if val_df is not None:\n",
    "        val_dataset = HingeSiameseDataset(val_df, tokenizer)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    else:\n",
    "        val_loader = None\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = WeightedHingeLoss(margin=margin)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = cont_loss_total = 0\n",
    "        train_correct = train_total = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            cve_input = {\n",
    "                'input_ids': batch['cve_input_ids'].to(device),\n",
    "                'attention_mask': batch['cve_attention_mask'].to(device)\n",
    "            }\n",
    "            tech_input = {\n",
    "                'input_ids': batch['tech_input_ids'].to(device),\n",
    "                'attention_mask': batch['tech_attention_mask'].to(device)\n",
    "            }\n",
    "            labels = batch['labels'].to(device)\n",
    "            weights = batch['role_weights'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: enhanced model returns (classifier_out, contrastive_loss)\n",
    "            outputs, cont_loss = model(cve_input, tech_input, labels)\n",
    "            \n",
    "            hinge_loss = criterion(outputs, labels, weights)\n",
    "            total_loss = hinge_loss + cont_loss * model.contrastive_weight\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += total_loss.item()\n",
    "            cont_loss_total += cont_loss.item()\n",
    "            preds = torch.sign(outputs)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_cont_loss = cont_loss_total / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.4f}, Contrastive Loss: {avg_cont_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        \n",
    "        if val_loader is not None:\n",
    "            val_acc, val_loss = validate_model(model, val_loader, criterion, device)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "                print(f\"Saved new best model with validation accuracy: {best_val_acc:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "                    break\n",
    "    \n",
    "    if val_loader is None or patience_counter < patience:\n",
    "        torch.save(model.state_dict(), \"final_model.pth\")\n",
    "    \n",
    "    plot_training_history(history)\n",
    "    return model\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model on validation set\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = val_correct = val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            cve_input = {\n",
    "                'input_ids': batch['cve_input_ids'].to(device),\n",
    "                'attention_mask': batch['cve_attention_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            tech_input = {\n",
    "                'input_ids': batch['tech_input_ids'].to(device),\n",
    "                'attention_mask': batch['tech_attention_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            labels = batch['labels'].to(device)\n",
    "            weights = batch['role_weights'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, cont_loss = model(cve_input, tech_input, labels)\n",
    "            \n",
    "            # Calculate loss\n",
    "            hinge_loss = criterion(outputs, labels, weights)\n",
    "            total_loss = hinge_loss + cont_loss * model.contrastive_weight\n",
    "            \n",
    "            val_loss += total_loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            preds = torch.sign(outputs)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    return val_correct/val_total, val_loss/len(val_loader)\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    if 'val_loss' in history and history['val_loss']:\n",
    "        plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves')\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    if 'val_acc' in history and history['val_acc']:\n",
    "        plt.plot(history['val_acc'], label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Curves')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "# 8. Modified Evaluation without FAISS - Focus on Test Results\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate model and output detailed results on test set\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # For metrics\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    all_outputs = []\n",
    "    test_correct = test_total = 0\n",
    "    \n",
    "    # Test sample storage for detailed analysis\n",
    "    test_samples = {\n",
    "        'cve_text': [],\n",
    "        'tech_text': [],\n",
    "        'true_label': [],\n",
    "        'predicted_label': [],\n",
    "        'confidence_score': []\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating on test set\"):\n",
    "            # Get batch data\n",
    "            cve_input = {\n",
    "                'input_ids': batch['cve_input_ids'].to(device),\n",
    "                'attention_mask': batch['cve_attention_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            tech_input = {\n",
    "                'input_ids': batch['tech_input_ids'].to(device),\n",
    "                'attention_mask': batch['tech_attention_mask'].to(device)\n",
    "            }\n",
    "            \n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(cve_input, tech_input, labels)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            preds = torch.sign(outputs)\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            \n",
    "            # Store samples for analysis\n",
    "            for i in range(len(batch['cve_input_ids'])):\n",
    "                test_samples['cve_text'].append(batch['CVE_text'][i])\n",
    "                test_samples['tech_text'].append(batch['Technique_text'][i])\n",
    "                test_samples['true_label'].append(float(labels[i].cpu().numpy()))\n",
    "                test_samples['predicted_label'].append(float(preds[i].cpu().numpy()))\n",
    "                test_samples['confidence_score'].append(float(outputs[i].cpu().numpy()))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Create a DataFrame for test results for easier analysis and output\n",
    "    test_results_df = pd.DataFrame(test_samples)\n",
    "    \n",
    "    # Convert labels from -1/1 to 0/1 for readability\n",
    "    test_results_df['true_label'] = (test_results_df['true_label'] + 1) / 2\n",
    "    test_results_df['predicted_label'] = (test_results_df['predicted_label'] + 1) / 2\n",
    "    \n",
    "    # Add a column for correct/incorrect predictions\n",
    "    test_results_df['correct'] = test_results_df['true_label'] == test_results_df['predicted_label']\n",
    "    \n",
    "    # Save detailed test results to CSV\n",
    "    test_results_df.to_csv('test_results_detailed.csv', index=False)\n",
    "    print(f\"Saved detailed test results to 'test_results_detailed.csv'\")\n",
    "    \n",
    "    # Classification report\n",
    "    all_true_01 = [(label + 1) / 2 for label in all_true]  # Convert -1/1 to 0/1\n",
    "    all_preds_01 = [(pred + 1) / 2 for pred in all_preds]  # Convert -1/1 to 0/1\n",
    "    \n",
    "    class_report = classification_report(all_true_01, all_preds_01, output_dict=True)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, metrics in class_report.items():\n",
    "        if label in ['0.0', '1.0']:\n",
    "            print(f\"Class {label}: Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1: {metrics['f1-score']:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_true_01, all_preds_01)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Sample analysis: Show some correct and incorrect examples\n",
    "    print(\"\\n=== Sample Correct Predictions ===\")\n",
    "    correct_samples = test_results_df[test_results_df['correct']].head(5)\n",
    "    for i, row in correct_samples.iterrows():\n",
    "        print(f\"True label: {int(row['true_label'])}, Predicted: {int(row['predicted_label'])}, Confidence: {row['confidence_score']:.4f}\")\n",
    "        print(f\"CVE excerpt: {row['cve_text'][:100]}...\")\n",
    "        print(f\"Technique excerpt: {row['tech_text'][:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    print(\"\\n=== Sample Incorrect Predictions ===\")\n",
    "    incorrect_samples = test_results_df[~test_results_df['correct']].head(5)\n",
    "    for i, row in incorrect_samples.iterrows():\n",
    "        print(f\"True label: {int(row['true_label'])}, Predicted: {int(row['predicted_label'])}, Confidence: {row['confidence_score']:.4f}\")\n",
    "        print(f\"CVE excerpt: {row['cve_text'][:100]}...\")\n",
    "        print(f\"Technique excerpt: {row['tech_text'][:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Distribution of confidence scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    correct_scores = test_results_df[test_results_df['correct']]['confidence_score']\n",
    "    incorrect_scores = test_results_df[~test_results_df['correct']]['confidence_score']\n",
    "    \n",
    "    plt.hist(correct_scores, alpha=0.7, label='Correct predictions', bins=20)\n",
    "    plt.hist(incorrect_scores, alpha=0.7, label='Incorrect predictions', bins=20)\n",
    "    plt.title('Distribution of Model Confidence Scores')\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.savefig('confidence_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Error analysis summary\n",
    "    print(\"\\n=== Error Analysis Summary ===\")\n",
    "    print(f\"Total test samples: {len(test_results_df)}\")\n",
    "    print(f\"Correct predictions: {len(test_results_df[test_results_df['correct']])} ({len(test_results_df[test_results_df['correct']])/len(test_results_df)*100:.2f}%)\")\n",
    "    print(f\"Incorrect predictions: {len(test_results_df[~test_results_df['correct']])} ({len(test_results_df[~test_results_df['correct']])/len(test_results_df)*100:.2f}%)\")\n",
    "    \n",
    "    # False positives and false negatives\n",
    "    false_positives = test_results_df[(test_results_df['true_label'] == 0) & (test_results_df['predicted_label'] == 1)]\n",
    "    false_negatives = test_results_df[(test_results_df['true_label'] == 1) & (test_results_df['predicted_label'] == 0)]\n",
    "    \n",
    "    print(f\"False positives: {len(false_positives)} ({len(false_positives)/len(test_results_df)*100:.2f}%)\")\n",
    "    print(f\"False negatives: {len(false_negatives)} ({len(false_negatives)/len(test_results_df)*100:.2f}%)\")\n",
    "    \n",
    "    return test_acc, test_results_df\n",
    "\n",
    "# Check if we should load an existing model\n",
    "def main():\n",
    "    \"\"\"Main function to run the SRL model training and evaluation pipeline\"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading SRL dataset...\")\n",
    "    try:\n",
    "        df = load_srl_dataset(\"siamese_samples_with_srl (6).json\")\n",
    "        if df.empty:\n",
    "            print(\"Error: Dataset is empty. Please check the data file.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Split data\n",
    "    try:\n",
    "        train_df, val_df, test_df = get_splits_for_model(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if we need to train or load a saved model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_path = \"best_model.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading pre-trained model from {model_path}\")\n",
    "        try:\n",
    "            model = EnhancedContrastiveSRLModel().to(device)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Training a new model instead...\")\n",
    "            model = train_hinge_model(\n",
    "                train_df=train_df,\n",
    "                val_df=val_df,\n",
    "                epochs=10,\n",
    "                batch_size=16,\n",
    "                margin=1.0,\n",
    "                patience=3,\n",
    "                lr=2e-5,\n",
    "                contrastive_weight=0.4\n",
    "            )\n",
    "    else:\n",
    "        print(\"No pre-trained model found. Training a new model...\")\n",
    "        model = train_hinge_model(\n",
    "            train_df=train_df,\n",
    "            val_df=val_df,\n",
    "            epochs=50,\n",
    "            batch_size=16,\n",
    "            margin=1.0,\n",
    "            patience=3,\n",
    "            lr=2e-5,\n",
    "            contrastive_weight=0.4\n",
    "        )\n",
    "    \n",
    "    # Create test dataset and dataloader\n",
    "    print(\"Preparing test data...\")\n",
    "    test_dataset = HingeSiameseDataset(test_df, tokenizer)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    test_acc, test_results_df = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Generate embeddings visualization\n",
    "    print(\"Generating embedding visualizations...\")\n",
    "    try:\n",
    "        # Sample a subset for visualization (t-SNE can be slow with large datasets)\n",
    "        vis_sample = test_df.sample(min(500, len(test_df))).reset_index(drop=True)\n",
    "        vis_dataset = HingeSiameseDataset(vis_sample, tokenizer)\n",
    "        vis_loader = DataLoader(vis_dataset, batch_size=16)\n",
    "        \n",
    "        # Extract embeddings\n",
    "        cve_embeddings = []\n",
    "        tech_embeddings = []\n",
    "        labels = []\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(vis_loader, desc=\"Extracting embeddings\"):\n",
    "                cve_input = {\n",
    "                    'input_ids': batch['cve_input_ids'].to(device),\n",
    "                    'attention_mask': batch['cve_attention_mask'].to(device)\n",
    "                }\n",
    "                tech_input = {\n",
    "                    'input_ids': batch['tech_input_ids'].to(device),\n",
    "                    'attention_mask': batch['tech_attention_mask'].to(device)\n",
    "                }\n",
    "                \n",
    "                # Get embeddings using the model's embedding extraction method\n",
    "                cve_emb = model.get_embeddings(cve_input)\n",
    "                tech_emb = model.get_embeddings(tech_input)\n",
    "                \n",
    "                cve_embeddings.extend(cve_emb)\n",
    "                tech_embeddings.extend(tech_emb)\n",
    "                labels.extend(batch['labels'].numpy())\n",
    "        \n",
    "        # Convert to arrays\n",
    "        cve_embeddings = np.array(cve_embeddings)\n",
    "        tech_embeddings = np.array(tech_embeddings)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Apply t-SNE for dimensionality reduction\n",
    "        print(\"Applying t-SNE for visualization...\")\n",
    "        tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "        \n",
    "        # Combine embeddings for visualization\n",
    "        combined_embeddings = np.vstack([cve_embeddings, tech_embeddings])\n",
    "        combined_labels = np.concatenate([labels, labels])\n",
    "        \n",
    "        # Add a type indicator (0 for CVE, 1 for Technique)\n",
    "        types = np.concatenate([np.zeros(len(cve_embeddings)), np.ones(len(tech_embeddings))])\n",
    "        \n",
    "        # Apply t-SNE\n",
    "        reduced_embeddings = tsne.fit_transform(combined_embeddings)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Convert to 0/1 label (from -1/+1)\n",
    "        binary_labels = (combined_labels + 1) / 2\n",
    "        \n",
    "        # Create a scatter plot with four categories:\n",
    "        # 1. CVE - Negative, 2. CVE - Positive, 3. Technique - Negative, 4. Technique - Positive\n",
    "        markers = {0: 'o', 1: '^'}  # circle for CVE, triangle for Technique\n",
    "        colors = {0: 'red', 1: 'blue'}  # red for negative, blue for positive\n",
    "        \n",
    "        for t in [0, 1]:  # type (CVE or Technique)\n",
    "            for l in [0, 1]:  # label (0 or 1)\n",
    "                mask = (types == t) & (binary_labels == l)\n",
    "                plt.scatter(\n",
    "                    reduced_embeddings[mask, 0],\n",
    "                    reduced_embeddings[mask, 1],\n",
    "                    marker=markers[t],\n",
    "                    c=colors[l],\n",
    "                    alpha=0.7,\n",
    "                    label=f\"{'CVE' if t == 0 else 'Technique'} - {'Negative' if l == 0 else 'Positive'}\"\n",
    "                )\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.title('t-SNE Visualization of CVE and Technique Embeddings')\n",
    "        plt.savefig('embeddings_visualization.png')\n",
    "        plt.close()\n",
    "        print(\"Saved embeddings visualization to 'embeddings_visualization.png'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating visualizations: {e}\")\n",
    "    \n",
    "    print(\"Pipeline completed successfully!\")\n",
    "\n",
    "# Run the main function if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7119698,
     "sourceId": 11372816,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
