{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch all exisiting CVE Information (Vulnerability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Define files to store the last processed index and failed indexes\n",
    "last_index_file = \"data/last_index.txt\"\n",
    "failed_batches_file = \"data/failed_batches.txt\"\n",
    "\n",
    "# Read the last start index if the file exists, otherwise start from 0\n",
    "if os.path.exists(last_index_file):\n",
    "    with open(last_index_file, \"r\") as f:\n",
    "        start_index = int(f.read().strip())\n",
    "else:\n",
    "    start_index = 0\n",
    "\n",
    "# Read previously failed batches if the file exists\n",
    "failed_batches = []\n",
    "if os.path.exists(failed_batches_file):\n",
    "    with open(failed_batches_file, \"r\") as f:\n",
    "        failed_batches = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "url = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "results_per_page = 1000  # Reduce batch size to avoid large response issues\n",
    "total_results = 279615  # Total CVEs\n",
    "all_cves = []\n",
    "max_retries = 5  # Number of retries per request\n",
    "\n",
    "# Function to save failed batches\n",
    "def save_failed_batches():\n",
    "    with open(failed_batches_file, \"w\") as f:\n",
    "        for idx in failed_batches:\n",
    "            f.write(f\"{idx}\\n\")\n",
    "\n",
    "# Try to process CVEs starting from the last index or failed batches\n",
    "while start_index < total_results or failed_batches:\n",
    "    # Get the next index to process (either from failed batches or continue)\n",
    "    if failed_batches:\n",
    "        start_index = failed_batches.pop(0)  # Start from the first failed batch\n",
    "    params = {\"startIndex\": start_index, \"resultsPerPage\": results_per_page}\n",
    "\n",
    "    for attempt in range(max_retries):  # Retry loop\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30, stream=True)  # Streaming response\n",
    "            response.raise_for_status()  # Raise error for bad status codes\n",
    "            \n",
    "            data = response.json()\n",
    "            all_cves.extend(data.get(\"vulnerabilities\", []))  # Extract and store CVEs\n",
    "            print(f\"Fetched {start_index}/{total_results} CVEs...\")\n",
    "\n",
    "            # Save the current index to resume from here in the future\n",
    "            with open(last_index_file, \"w\") as f:\n",
    "                f.write(str(start_index))\n",
    "\n",
    "            time.sleep(1)  # Avoid hitting rate limits\n",
    "            break  # Exit retry loop on success\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data (attempt {attempt+1}/{max_retries}): {e}\")\n",
    "            if attempt == max_retries - 1:  # Max retries reached\n",
    "                print(f\"Failed to fetch batch starting at {start_index}. Adding to failed batches.\")\n",
    "                failed_batches.append(start_index)  # Add to failed batches list\n",
    "                save_failed_batches()  # Save the failed batches\n",
    "            time.sleep(5 * (attempt + 1))  # Exponential backoff before retrying\n",
    "\n",
    "    # Move to the next batch if current batch is successful\n",
    "    start_index += results_per_page\n",
    "\n",
    "# Save all CVEs to a file\n",
    "with open(\"data/all_cves.json\", \"w\") as f:\n",
    "    json.dump({\"vulnerabilities\": all_cves}, f, indent=4)\n",
    "\n",
    "print(f\"Saved {len(all_cves)} CVEs to data/all_cves.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate the fetched Detailed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved: all_cves.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load CVE data from the JSON file\n",
    "with open(\"all_cves.json\", \"r\") as f:\n",
    "    cve_data = json.load(f)\n",
    "\n",
    "# Extract relevant fields\n",
    "cve_list = []\n",
    "for item in cve_data.get(\"vulnerabilities\", []):\n",
    "    cve_id = item[\"cve\"][\"id\"]\n",
    "    \n",
    "    # Extract description (get English description if available)\n",
    "    descriptions = item[\"cve\"].get(\"descriptions\", [])\n",
    "    description = next((d[\"value\"] for d in descriptions if d[\"lang\"] == \"en\"), \"No description available\")\n",
    "    \n",
    "    # Extract CVSS details (try CVSS v3 first, then v2 if v3 is missing)\n",
    "    metrics = item[\"cve\"].get(\"metrics\", {})\n",
    "    \n",
    "    cvss_v3 = metrics.get(\"cvssMetricV31\", metrics.get(\"cvssMetricV30\", []))\n",
    "    if cvss_v3:\n",
    "        cvss_v3 = cvss_v3[0].get(\"cvssData\", {})\n",
    "    else:\n",
    "        cvss_v2 = metrics.get(\"cvssMetricV2\", [])\n",
    "        cvss_v3 = cvss_v2[0].get(\"cvssData\", {}) if cvss_v2 else {}\n",
    "\n",
    "    base_score = cvss_v3.get(\"baseScore\", \"N/A\")\n",
    "    confidentiality_impact = cvss_v3.get(\"confidentialityImpact\", \"N/A\")\n",
    "    integrity_impact = cvss_v3.get(\"integrityImpact\", \"N/A\")\n",
    "    availability_impact = cvss_v3.get(\"availabilityImpact\", \"N/A\")\n",
    "\n",
    "    # Extract CWE ID if available\n",
    "    weaknesses = item[\"cve\"].get(\"weaknesses\", [])\n",
    "    cwe_id = weaknesses[0][\"description\"][0][\"value\"] if weaknesses else \"N/A\"\n",
    "\n",
    "    # Append data to list\n",
    "    cve_list.append([cve_id, description, base_score, confidentiality_impact, integrity_impact, availability_impact, cwe_id])\n",
    "\n",
    "# Create DataFrame\n",
    "# Create DataFrame\n",
    "columns = [\"CVE ID\", \"Description\", \"CVSS Base Score\", \"Confidentiality Impact\", \"Integrity Impact\", \"Availability Impact\", \"CWE ID\"]\n",
    "df = pd.DataFrame(cve_list, columns=columns)\n",
    "\n",
    "# Keep only 'CVE ID' and 'Description' columns\n",
    "df = df[[\"CVE ID\", \"Description\"]]\n",
    "\n",
    "# Save to Excel with updated filename\n",
    "df.to_excel(\"../Data/CleanedUpdates2.xlsx\", index=False)\n",
    "\n",
    "print(\"Excel file saved: CleanedUpdates2.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
